1、线程池使用：CPU密集型和IO密集型<br>
cpu密集型：cpu使用率较高（也就是一些复杂运算，逻辑处理），所以线程数一般只需要cpu核数的线程就可以了。 这一类型的在开发中多出现的一些业务复杂计算和逻辑处理过程中。<br>
I/O密集型：cpu使用率较低，程序中会存在大量I/O操作占据时间，导致线程空余时间出来，所以通常就需要开cpu核数的两倍的线程， 当线程进行I/O操作cpu空暇时启用其他线程继续使用cpu，提高cpu使用率 通过上述可以总结出：线程的最佳数量： 最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目 线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程。这一类型在开发中主要出现在一些读写操作频繁的业务逻辑中。<br>
1：高并发、任务执行时间短的业务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换<br>
2：并发不高、任务执行时间长的业务这就需要区分开看了：<br>
a）假如是业务时间长集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以适当加大线程池中的线程数目，让CPU处理更多的业务<br>
b）假如是业务时间长集中在计算操作上，也就是计算密集型任务，这个就没办法了，和（1）一样吧，线程池中的线程数设置得少一些，减少线程上下文的切换<br>
3：并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，业务执行时间长的问题，也可能需要分析一下，看看能不能使用中间件（任务时间过长的可以考虑拆分逻辑放入队列等操作）对任务进行拆分和解耦。<br>

2、ThreadLocal<br>
每个thread中都存在一个map, map的类型是ThreadLocal.ThreadLocalMap. Map中的key为一个threadlocal实例. 这个Map的确使用了弱引用,不过弱引用只是针对key. 每个key都弱引用指向threadlocal. 当把threadlocal实例置为null以后,没有任何强引用指向threadlocal实例,所以threadlocal将会被gc回收. 但是,我们的value却不能回收,因为存在一条从current thread连接过来的强引用. 只有当前thread结束以后, current thread就不会存在栈中,强引用断开, Current Thread, Map, value将全部被GC回收.<br>
所以得出一个结论就是只要这个线程对象被gc回收，就不会出现内存泄露，但在threadLocal设为null和线程结束这段时间不会被回收的，就发生了我们认为的内存泄露。其实这是一个对概念理解的不一致，也没什么好争论的。最要命的是线程对象不被回收的情况，这就发生了真正意义上的内存泄露。比如使用线程池的时候，线程结束是不会销毁的，会再次使用的。就可能出现内存泄露。<br>
PS.Java为了最小化减少内存泄露的可能性和影响，在ThreadLocal的get,set的时候都会清除线程Map里所有key为null的value。所以最怕的情况就是，threadLocal对象设null了，开始发生“内存泄露”，然后使用线程池，这个线程结束，线程放回线程池中不销毁，这个线程一直不被使用，或者分配使用了又不再调用get,set方法，那么这个期间就会发生真正的内存泄露。<br>



3、怎么实现死锁，怎么避免死锁（导致线程死锁的原因？怎么解除线程死锁。）<br>
在死锁时，线程间相互等待资源，而又不释放自身的资源，导致无穷无尽的等待，其结果是系统任务永远无法执行完成。死锁问题是在多线程开发中应该坚决避免和杜绝的问题。 <br>
一般来说，要出现死锁问题需要满足以下条件： <br>
1. 互斥条件：一个资源每次只能被一个线程使用。 <br>
2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 <br>
3. 不剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺。 <br>
4. 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。 <br>
只要破坏死锁 4 个必要条件之一中的任何一个，死锁问题就能被解决。 <br>
1. 最简单、最常用的方法就是进行系统的重新启动，不过这种方法代价很大，它意味着在这之前所有的进程已经完成的计算工作都将付之东流，包括参与死锁的那些进程，以及未参与死锁的进程；<br>
2. 撤消进程，剥夺资源。终止参与死锁的进程，收回它们占有的资源，从而解除死锁。这时又分两种情况：一次性撤消参与死锁的全部进程，剥夺全部资源；或者逐步撤消参与死锁的进程，逐步收回死锁进程占有的资源。一般来说，选择逐步撤消的进程时要按照一定的原则进行，目的是撤消那些代价最小的进程，比如按进程的优先级确定进程的代价；考虑进程运行时的代价和与此进程相关的外部作业的代价等因素；<br>
3. 进程回退策略，即让参与死锁的进程回退到没有发生死锁前某一点处，并由此点处继续执行，以求再次执行时不再发生死锁。虽然这是个较理想的办法，但是操作起来系统开销极大，要有堆栈这样的机构记录进程的每一步变化，以便今后的回退，有时这是无法做到的。<br>


4、多线程的几种实现方式，什么是线程安全。<br>
实现runable接口，继承thread类。 <br>

5、volatile 的原理，作用，能代替锁么。<br>
Volatile利用内存栅栏机制来保持变量的一致性。不能代替锁，其只具备数据可见性一致性，不具备原子性。 <br>

6、画一个线程的生命周期状态图。<br>
新建，可运行，运行中， 睡眠，阻塞，等待，死亡。 <br>

7、sleep 和 wait 的区别。<br>
Sleep是休眠线程，wait是等待，sleep是thread的静态方法，wait则是object的方法。 <br>
Sleep依旧持有锁，并在指定时间自动唤醒。wait则释放锁。 <br>

8、Lock 与 Synchronized 的区别。<br>
首先两者都保持了并发场景下的原子性和可见性，区别则是synchronized的释放锁机制是交由其自身控制，且互斥性在某些场景下不符合逻辑，无法进行干预，不可人为中断等。 <br>
而lock常用的则有ReentrantLock和ReadWriteLock两者，添加了类似锁投票、定时锁等候和可中断锁等候的一些特性。此外，它还提供了在激烈争用情况下更佳的性能。 <br>

9、synchronized 的原理是什么，解释以下名词：重排序，自旋锁，偏向锁，轻量级锁，可重入锁，公平锁，非公平锁，乐观锁，悲观锁。<br>
Synchronized底层是通过监视器的enter和exit实现 <br>

10、用过哪些原子类，他们的原理是什么。<br>
AtomicInteger； AtomicLong； AtomicReference； AtomicBoolean；基于CAS原语实现 ，比较并交换、加载链接/条件存储，最坏的情况下是旋转锁 <br>

11、用过线程池吗，newCache 和 newFixed 有什么区别，他们的原理简单概括下，构造函数的各个参数的含义是什么，比如 coreSize，maxsize 等<br>
newSingleThreadExecutor返回以个包含单线程的Executor,将多个任务交给此Exector时，这个线程处理完一个任务后接着处理下一个任务，若该线程出现异常，将会有一个新的线程来替代。<br>
newFixedThreadPool返回一个包含指定数目线程的线程池，如果任务数量多于线程数目，那么没有没有执行的任务必须等待，直到有任务完成为止。<br>
newCachedThreadPool根据用户的任务数创建相应的线程来处理，该线程池不会对线程数目加以限制，完全依赖于JVM能创建线程的数量，可能引起内存不足。 <br>
底层是基于ThreadPoolExecutor实现，借助ReentrantLock保证并发。 <br>
coreSize核心线程数，maxsize最大线程数。 <br>

12、线程池的关闭方式有几种，各自的区别是什么。<br>
Shutdown shutdownNow tryTerminate 清空工作队列，终止线程池中各个线程，销毁线程池 <br>

13、假如有一个第三方接口，有很多个线程去调用获取数据，现在规定每秒钟最多有 10 个线程同时调用它，如何做到。<br>
ScheduledThreadPoolExecutor 设置定时，进行调度。 <br>
public ScheduledThreadPoolExecutor(int corePoolSize, <br>
ThreadFactory threadFactory) { <br>
super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS, <br>
new DelayedWorkQueue(), threadFactory); <br>
}<br>

14、用三个线程按顺序循环打印 abc 三个字母，比如 abcabcabc。<br>
线程池按顺序提交任务<br>

15、ThreadLocal 用过么，用途是什么，原理是什么，用的时候要注意什么。<br>
ThreadLocal的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。 <br>

16、如果让你实现一个并发安全的链表，你会怎么做。<br>
ConcurrentLinkedQueue <br>

18、讲讲 java 同步机制的 wait 和 notify。<br>
首先这两个方法只能在同步代码块中调用，wait会释放掉对象锁，等待notify唤醒。 <br>

19、countdowlatch 和 cyclicbarrier 的内部原理和用法，以及相互之间的差别。<br>
CountDownLatch是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它运行一个或者多个线程一直处于等待状态。 <br>
CyclicBarrier要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。 <br>
CyclicBarrier初始化的时候，设置一个屏障数。线程调用await()方法的时候，这个线程就会被阻塞，当调用await()的线程数量到达屏障数的时候，主线程就会取消所有被阻塞线程的状态。 <br>
前者是递减，不可循环，后者是递加，可循环用 <br>
countdowlatch 基于abq cb基于ReentrantLock Condition <br>

20、使用 synchronized 修饰静态方法和非静态方法有什么区别。<br>
对象锁和类锁 <br>

21、简述 ConcurrentLinkedQueue LinkedBlockingQueue 的用处和不同之处。<br>
LinkedBlockingQueue 是一个基于单向链表的、范围任意的（其实是有界的）、FIFO 阻塞队列。 <br>
ConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当我们添加一个元素的时候，它会添加到队列的尾部，当我们获取一个元素时，它会返回队列头部的元素。它采用了“wait－free”算法来实现，该算法在Michael & Scott算法上进行了一些修改, <br>

22、线程池为什是调用 run() 而不是 start()<br>
执行了 start() 方法后操作系统才会给我们创建一个独立的线程来运行，而 run() 方法只是一个普通的方法调用<br>
假设这里是调用的 Runnable 的 start 方法，那会发生什么事情。如果我们往一个核心、最大线程数为 2 的线程池里丢了 1000 个任务，那么它会额外的创建 1000 个线程，同时每个任务都是异步执行的，一下子就执行完毕了。从而没法做到由这两个 Worker 线程来调度这 1000 个任务，而只有当做一个同步阻塞的 run() 方法调用时才能满足这个要求。<br>

23、怎么中断线程？<br>
interrupt();（阻塞时退出阻塞状态）<br>
使用共享变量的方式：在这种方式中，之所以引入共享变量，是因为该变量可以被多个执行相同任务的线程用来作为是否中断的信号，通知中断线程的执行。<br>


JDK1.6 之后的底层优化
JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。

锁主要存在四中状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

### 无锁状态 -> 偏向锁状态 -> 轻量级锁状态 -> 自旋锁 -> 重量级锁状态
轻量级锁：所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。
Java并发编程：Synchronized底层优化（偏向锁、轻量级锁）：https://www.cnblogs.com/paddix/p/5405678.html

# 锁消除
锁消除理解起来很简单，它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。

# 锁粗化
原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小，——直在共享数据的实际作用域才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待线程也能尽快拿到锁。
大部分情况下，上面的原则都是没有问题的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，那么会带来很多不必要的性能消耗。
